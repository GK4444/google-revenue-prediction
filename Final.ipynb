{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distributed-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import lightgbm as lgb\n",
    "from sklearn.externals import joblib \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-naples",
   "metadata": {},
   "source": [
    "# fun1 which returns predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ranking-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_1(query_pt):\n",
    "    start=time.time()\n",
    "    # load light gb regressor model\n",
    "    with open('../lgb_agg_final.pickle','rb') as f:\n",
    "        lgb_regressor = pickle.load(f)\n",
    "    # load standardScaler object\n",
    "    scaler = joblib.load('standarising_scaler.pkl')\n",
    "    # DATA COLUMNS\n",
    "    data_columns = ['channelGrouping', 'customDimensions', 'date', 'fullVisitorId', 'visitId', 'visitNumber', \n",
    "                    'visitStartTime', 'device.browser', 'device.operatingSystem', 'device.isMobile', \n",
    "                    'device.deviceCategory', 'geoNetwork.continent', 'geoNetwork.subContinent', \n",
    "                    'geoNetwork.country', 'geoNetwork.region', 'geoNetwork.metro', 'geoNetwork.city', \n",
    "                    'geoNetwork.networkDomain', 'totals.hits', 'totals.pageviews', 'totals.sessionQualityDim',\n",
    "                    'totals.timeOnSite', 'totals.transactions', 'totals.transactionRevenue',\n",
    "                    'trafficSource.campaign', 'trafficSource.source', 'trafficSource.medium', \n",
    "                    'trafficSource.keyword', 'trafficSource.referralPath']\n",
    "    test_df = query_pt[data_columns].copy()#pd.DataFrame(data=[query_pt.values], columns=data_columns)\n",
    "    # converting single row series into dataframe\n",
    "    if isinstance(test_df,pd.Series):\n",
    "        test_df = pd.DataFrame([test_df])\n",
    "    # NUMERIC DATA\n",
    "    numeric_feat = ['totals.hits','totals.pageviews','totals.timeOnSite', 'totals.transactions',\n",
    "                'totals.transactionRevenue', 'totals.sessionQualityDim']\n",
    "    for feature in numeric_feat:\n",
    "        # convert to float32\n",
    "        test_df[feature] = test_df[feature].astype('float32')\n",
    "        # fill missing values\n",
    "        test_df[feature].fillna(0,inplace=True)\n",
    "        if feature not in ['totals.transactionRevenue']: \n",
    "            print(f'Normalising {feature} numeric feature....')\n",
    "            # transform numeric features using trained scaler object\n",
    "            test_df[feature] = scaler.transform(test_df[feature].values.reshape(-1, 1))\n",
    "    print(f'DONE: Standarization of numeric features completed.')     \n",
    "    # CATEGORICAL DATA\n",
    "    object_cols = list(test_df.select_dtypes(include=['object', 'bool']).columns)\n",
    "            \n",
    "    # creating separate category 'others' for missing data\n",
    "    test_df['geoNetwork.region'].replace(['not available in demo dataset', '(not set)'], 'others', inplace=True)\n",
    "    test_df['geoNetwork.metro'].replace(['not available in demo dataset', '(not set)'], 'others', inplace=True)\n",
    "    test_df['geoNetwork.city'].replace(['not available in demo dataset', '(not set)'], 'others', inplace=True)\n",
    "    test_df['trafficSource.keyword'].replace([np.nan,'(not provided)'], 'others',inplace=True)\n",
    "    test_df['trafficSource.referralPath'].fillna('others',inplace=True)\n",
    "    \n",
    "    # source : https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n",
    "    for feature in object_cols:\n",
    "        if feature != 'fullVisitorId':\n",
    "            # intitalizing label encoder object\n",
    "            label_encoder = preprocessing.LabelEncoder()\n",
    "            # reading already saved files       \n",
    "            label_encoder.classes_ = np.load(feature+'.npy')\n",
    "            # transforming that feature\n",
    "            print(f\"Label encoding {feature}....\")\n",
    "            test_df[feature] = label_encoder.transform(list(test_df[feature].values.astype('str')))\n",
    "    print(f\"DONE: Label encoding for categorical features completed.\")\n",
    "    \n",
    "    # FEATURE ENGINEERING\n",
    "    # list of categorical features whose median values would be used as new feature\n",
    "    median_features = ['channelGrouping','device.browser','device.operatingSystem','geoNetwork.country',\n",
    "                       'customDimensions','geoNetwork.continent', 'geoNetwork.subContinent','geoNetwork.region',\n",
    "                       'geoNetwork.metro','geoNetwork.city','geoNetwork.networkDomain']\n",
    "    # list of features whose sum, mean, standard deviation would be used as new features\n",
    "    sum_features = ['totals.hits','totals.pageviews','totals.timeOnSite','totals.transactions']\n",
    "\n",
    "    mean_features = ['totals.hits','totals.pageviews','totals.sessionQualityDim']\n",
    "\n",
    "    std_features =  ['totals.hits','totals.pageviews']\n",
    "    # define window intervals\n",
    "    # setting target period with gap of 2 months\n",
    "    # Duration : 1 Aug 2016 (start of train date) to 1 Dec 2018 (start of kaggle private date)\n",
    "    target_period = pd.date_range(start='2016-08-01',end='2018-12-01', freq='2MS')\n",
    "    # Shift train period by 168 days\n",
    "    train_period = target_period.to_series().shift(periods=-168, freq='d',axis= 0)\n",
    "    # Set start date of window using the dates which are greater than the start of our TRAIN DATE\n",
    "    # We will use these dates to calculate the time features with respect to 'visitStartTime',\n",
    "    # which is given in POSIX time format.\n",
    "    # So we will convert the datetime object to POSIX time format using :- .astype('int')//10**9\n",
    "    start_window = train_period[train_period.index>np.datetime64('2016-08-01')].astype('int')//10**9\n",
    "    # Set end date of window such that gap of 45 days is maintained with target period\n",
    "    end_window = target_period.to_series().shift(periods=-45, freq='d',axis= 0)[3:]\n",
    "    \n",
    "    # GROUPING DATA FOR EACH USER\n",
    "    # taking median of categorical features\n",
    "    median_features_data = test_df.groupby('fullVisitorId')[median_features].median().add_suffix('_median')\n",
    "\n",
    "    # TIME FEATURES\n",
    "    # first and last visit time in the given window is calculated by subtracting the start of the window\n",
    "    visit_time = test_df.groupby('fullVisitorId')['visitStartTime'].agg(['first','last']) \\\n",
    "                            .sub(start_window.values[-1]).abs().add_suffix('_time')\n",
    "\n",
    "    # time difference is time between the first and last visit of the user \n",
    "    time_diff = test_df.groupby('fullVisitorId')['visitStartTime'].apply(lambda x: x.max() - x.min()) \\\n",
    "                            .rename('time_diff')\n",
    "\n",
    "    # taking sum, mean, standard deviation of numerical features\n",
    "    sum_numerical_features = test_df.groupby('fullVisitorId')[sum_features].sum().add_suffix('_sum')\n",
    "    mean_numerical_features = test_df.groupby('fullVisitorId')[mean_features].mean().add_suffix('_mean')\n",
    "    std_numerical_features = test_df.groupby('fullVisitorId')[std_features].std(ddof=0).add_suffix('_std')\n",
    "\n",
    "    # combining new feature into a dataframe\n",
    "    test_x = pd.concat([median_features_data,visit_time, time_diff,sum_numerical_features,\n",
    "                         mean_numerical_features, std_numerical_features], axis=1).reset_index()\n",
    "\n",
    "    # removing visitorId from test set\n",
    "    test_x.drop(['fullVisitorId'],inplace=True, axis=1,errors='ignore')\n",
    "    test_x = test_x.astype('int')\n",
    "    test_y = test_df['totals.transactionRevenue']\n",
    "    print(f'DONE: Time window feature engineering completed.')\n",
    "    \n",
    "    # get predictions\n",
    "    predictions = lgb_regressor.predict(test_x)\n",
    "    predictions[predictions<0]=0\n",
    "    end = time.time()\n",
    "    print(f'Prediction done in {end-start} secs.')\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "metropolitan-quarter",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalising totals.hits numeric feature....\n",
      "Normalising totals.pageviews numeric feature....\n",
      "Normalising totals.timeOnSite numeric feature....\n",
      "Normalising totals.transactions numeric feature....\n",
      "Normalising totals.sessionQualityDim numeric feature....\n",
      "DONE: Standarization of numeric features completed.\n",
      "Label encoding channelGrouping....\n",
      "Label encoding customDimensions....\n",
      "Label encoding device.browser....\n",
      "Label encoding device.operatingSystem....\n",
      "Label encoding device.isMobile....\n",
      "Label encoding device.deviceCategory....\n",
      "Label encoding geoNetwork.continent....\n",
      "Label encoding geoNetwork.subContinent....\n",
      "Label encoding geoNetwork.country....\n",
      "Label encoding geoNetwork.region....\n",
      "Label encoding geoNetwork.metro....\n",
      "Label encoding geoNetwork.city....\n",
      "Label encoding geoNetwork.networkDomain....\n",
      "Label encoding trafficSource.campaign....\n",
      "Label encoding trafficSource.source....\n",
      "Label encoding trafficSource.medium....\n",
      "Label encoding trafficSource.keyword....\n",
      "Label encoding trafficSource.referralPath....\n",
      "DONE: Label encoding for categorical features completed.\n",
      "DONE: Time window feature engineering completed.\n",
      "Prediction done in 0.21936488151550293 secs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_org = pd.read_csv('test_5000.csv')\n",
    "query_pt = test_org.loc[0]\n",
    "preds = final_fun_1(query_pt)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-postcard",
   "metadata": {},
   "source": [
    "# fun2 which returns rmse score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ecological-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_2(test_df, original_target):\n",
    "    start=time.time()\n",
    "    # load light gb regressor model\n",
    "    with open('../lgb_agg_final.pickle','rb') as f:\n",
    "        lgb_regressor = pickle.load(f)\n",
    "    # load standardScaler object\n",
    "    scaler = joblib.load('standarising_scaler.pkl')\n",
    "    # DATA COLUMNS\n",
    "    data_columns = ['channelGrouping', 'customDimensions', 'date', 'fullVisitorId', 'visitId', 'visitNumber', \n",
    "                    'visitStartTime', 'device.browser', 'device.operatingSystem', 'device.isMobile', \n",
    "                    'device.deviceCategory', 'geoNetwork.continent', 'geoNetwork.subContinent', \n",
    "                    'geoNetwork.country', 'geoNetwork.region', 'geoNetwork.metro', 'geoNetwork.city', \n",
    "                    'geoNetwork.networkDomain', 'totals.hits', 'totals.pageviews', 'totals.sessionQualityDim',\n",
    "                    'totals.timeOnSite', 'totals.transactions', 'totals.transactionRevenue',\n",
    "                    'trafficSource.campaign', 'trafficSource.source', 'trafficSource.medium', \n",
    "                    'trafficSource.keyword', 'trafficSource.referralPath']\n",
    "    test_df = query_pt[data_columns].copy()#pd.DataFrame(data=[query_pt.values], columns=data_columns)\n",
    "    # converting single row series into dataframe\n",
    "    if isinstance(test_df,pd.Series):\n",
    "        test_df = pd.DataFrame([test_df])\n",
    "    # NUMERIC DATA\n",
    "    numeric_feat = ['totals.hits','totals.pageviews','totals.timeOnSite', 'totals.transactions',\n",
    "                'totals.transactionRevenue', 'totals.sessionQualityDim']\n",
    "    for feature in numeric_feat:\n",
    "        # convert to float32\n",
    "        test_df[feature] = test_df[feature].astype('float32')\n",
    "        # fill missing values\n",
    "        test_df[feature].fillna(0,inplace=True)\n",
    "        if feature not in ['totals.transactionRevenue']: \n",
    "            print(f'Normalising {feature} numeric feature....')\n",
    "            # transform numeric features using trained scaler object\n",
    "            test_df[feature] = scaler.transform(test_df[feature].values.reshape(-1, 1))\n",
    "    print(f'DONE: Standarization of numeric features completed.')     \n",
    "    # CATEGORICAL DATA\n",
    "    object_cols = list(test_df.select_dtypes(include=['object', 'bool']).columns)\n",
    "            \n",
    "    # creating separate category 'others' for missing data\n",
    "    test_df['geoNetwork.region'].replace(['not available in demo dataset', '(not set)'], 'others', inplace=True)\n",
    "    test_df['geoNetwork.metro'].replace(['not available in demo dataset', '(not set)'], 'others', inplace=True)\n",
    "    test_df['geoNetwork.city'].replace(['not available in demo dataset', '(not set)'], 'others', inplace=True)\n",
    "    test_df['trafficSource.keyword'].replace([np.nan,'(not provided)'], 'others',inplace=True)\n",
    "    test_df['trafficSource.referralPath'].fillna('others',inplace=True)\n",
    "    \n",
    "    # source : https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n",
    "    for feature in object_cols:\n",
    "        if feature != 'fullVisitorId':\n",
    "            # intitalizing label encoder object\n",
    "            label_encoder = preprocessing.LabelEncoder()\n",
    "            # reading already saved files       \n",
    "            label_encoder.classes_ = np.load(feature+'.npy')\n",
    "            # transforming that feature\n",
    "            print(f\"Label encoding {feature}....\")\n",
    "            test_df[feature] = label_encoder.transform(list(test_df[feature].values.astype('str')))\n",
    "    print(f\"DONE: Label encoding for categorical features completed.\")\n",
    "    \n",
    "    # FEATURE ENGINEERING\n",
    "    # list of categorical features whose median values would be used as new feature\n",
    "    median_features = ['channelGrouping','device.browser','device.operatingSystem','geoNetwork.country',\n",
    "                       'customDimensions','geoNetwork.continent', 'geoNetwork.subContinent','geoNetwork.region',\n",
    "                       'geoNetwork.metro','geoNetwork.city','geoNetwork.networkDomain']\n",
    "    # list of features whose sum, mean, standard deviation would be used as new features\n",
    "    sum_features = ['totals.hits','totals.pageviews','totals.timeOnSite','totals.transactions']\n",
    "\n",
    "    mean_features = ['totals.hits','totals.pageviews','totals.sessionQualityDim']\n",
    "\n",
    "    std_features =  ['totals.hits','totals.pageviews']\n",
    "    # define window intervals\n",
    "    # setting target period with gap of 2 months\n",
    "    # Duration : 1 Aug 2016 (start of train date) to 1 Dec 2018 (start of kaggle private date)\n",
    "    target_period = pd.date_range(start='2016-08-01',end='2018-12-01', freq='2MS')\n",
    "    # Shift train period by 168 days\n",
    "    train_period = target_period.to_series().shift(periods=-168, freq='d',axis= 0)\n",
    "    # Set start date of window using the dates which are greater than the start of our TRAIN DATE\n",
    "    # We will use these dates to calculate the time features with respect to 'visitStartTime',\n",
    "    # which is given in POSIX time format.\n",
    "    # So we will convert the datetime object to POSIX time format using :- .astype('int')//10**9\n",
    "    start_window = train_period[train_period.index>np.datetime64('2016-08-01')].astype('int')//10**9\n",
    "    # Set end date of window such that gap of 45 days is maintained with target period\n",
    "    end_window = target_period.to_series().shift(periods=-45, freq='d',axis= 0)[3:]\n",
    "    \n",
    "    # GROUPING DATA FOR EACH USER\n",
    "    # taking median of categorical features\n",
    "    median_features_data = test_df.groupby('fullVisitorId')[median_features].median().add_suffix('_median')\n",
    "\n",
    "    # TIME FEATURES\n",
    "    # first and last visit time in the given window is calculated by subtracting the start of the window\n",
    "    visit_time = test_df.groupby('fullVisitorId')['visitStartTime'].agg(['first','last']) \\\n",
    "                            .sub(start_window.values[-1]).abs().add_suffix('_time')\n",
    "\n",
    "    # time difference is time between the first and last visit of the user \n",
    "    time_diff = test_df.groupby('fullVisitorId')['visitStartTime'].apply(lambda x: x.max() - x.min()) \\\n",
    "                            .rename('time_diff')\n",
    "\n",
    "    # taking sum, mean, standard deviation of numerical features\n",
    "    sum_numerical_features = test_df.groupby('fullVisitorId')[sum_features].sum().add_suffix('_sum')\n",
    "    mean_numerical_features = test_df.groupby('fullVisitorId')[mean_features].mean().add_suffix('_mean')\n",
    "    std_numerical_features = test_df.groupby('fullVisitorId')[std_features].std(ddof=0).add_suffix('_std')\n",
    "\n",
    "    # combining new feature into a dataframe\n",
    "    test_x = pd.concat([median_features_data,visit_time, time_diff,sum_numerical_features,\n",
    "                         mean_numerical_features, std_numerical_features], axis=1).reset_index()\n",
    "\n",
    "    # removing visitorId from test set\n",
    "    test_x.drop(['fullVisitorId'],inplace=True, axis=1,errors='ignore')\n",
    "    test_x = test_x.astype('int')\n",
    "    test_y = test_df['totals.transactionRevenue']\n",
    "    print(f'DONE: Time window feature engineering completed.')\n",
    "    \n",
    "    # get predictions\n",
    "    predictions = lgb_regressor.predict(test_x)\n",
    "    predictions[predictions<0]=0\n",
    "    end = time.time()\n",
    "    print(f'Prediction done in {end-start} secs.')\n",
    "    if not isinstance(original_target, pd.Series):\n",
    "        original_target = pd.Series(original_target)\n",
    "    # get rmse score\n",
    "    rmse = mean_squared_error(np.log1p(original_target), predictions, squared=False)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "single-british",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalising totals.hits numeric feature....\n",
      "Normalising totals.pageviews numeric feature....\n",
      "Normalising totals.timeOnSite numeric feature....\n",
      "Normalising totals.transactions numeric feature....\n",
      "Normalising totals.sessionQualityDim numeric feature....\n",
      "DONE: Standarization of numeric features completed.\n",
      "Label encoding channelGrouping....\n",
      "Label encoding customDimensions....\n",
      "Label encoding device.browser....\n",
      "Label encoding device.operatingSystem....\n",
      "Label encoding device.isMobile....\n",
      "Label encoding device.deviceCategory....\n",
      "Label encoding geoNetwork.continent....\n",
      "Label encoding geoNetwork.subContinent....\n",
      "Label encoding geoNetwork.country....\n",
      "Label encoding geoNetwork.region....\n",
      "Label encoding geoNetwork.metro....\n",
      "Label encoding geoNetwork.city....\n",
      "Label encoding geoNetwork.networkDomain....\n",
      "Label encoding trafficSource.campaign....\n",
      "Label encoding trafficSource.source....\n",
      "Label encoding trafficSource.medium....\n",
      "Label encoding trafficSource.keyword....\n",
      "Label encoding trafficSource.referralPath....\n",
      "DONE: Label encoding for categorical features completed.\n",
      "DONE: Time window feature engineering completed.\n",
      "Prediction done in 0.21231985092163086 secs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_org = pd.read_csv('test_5000.csv')\n",
    "query_pt = test_org.loc[0]\n",
    "rmse = final_fun_2(query_pt,query_pt['totals.transactionRevenue'])\n",
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
